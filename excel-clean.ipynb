{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking file: data\\TX_CAID_Network3 90%_07.01.24.xlsx\n",
      "Sheets available in data\\TX_CAID_Network3 90%_07.01.24.xlsx: ['CAID']\n",
      "Columns in sheet CAID: ['state', 'county', 'facility or provider', 'providertype', 'metaccess']\n",
      "Checking file: data\\TX_CAID_Network3 90%_08.15.24.xlsx\n",
      "Sheets available in data\\TX_CAID_Network3 90%_08.15.24.xlsx: ['CAID']\n",
      "Columns in sheet CAID: ['state', 'county', 'facility or provider', 'providertype', 'metaccess']\n",
      "Checking file: data\\TX_MA_H09156 Network2_08.2.24.xlsx\n",
      "Sheets available in data\\TX_MA_H09156 Network2_08.2.24.xlsx: ['MA']\n",
      "Columns in sheet MA: ['state', 'county', 'provider or facility', 'specdesc', 'metaccess', 'metproviders', 'metoverall']\n",
      "Checking file: data\\TX_MA_H09156 Network2_07.15.24.xlsx\n",
      "Sheets available in data\\TX_MA_H09156 Network2_07.15.24.xlsx: ['MA']\n",
      "Columns in sheet MA: ['state', 'county', 'provider or facility', 'specdesc', 'metaccess', 'metproviders', 'metoverall']\n",
      "Combined DataFrame:\n",
      "     state       county  metcombined provider_or_facility  \\\n",
      "0       TX     Amarillo            1             Provider   \n",
      "1       TX      El Paso            1             Provider   \n",
      "2       MT     Missoula            1             Provider   \n",
      "3       TX      Lubbock            1             Facility   \n",
      "4       NM  Albuquerque            0             Provider   \n",
      "...    ...          ...          ...                  ...   \n",
      "3995    TX  San Antonio            0             Provider   \n",
      "3996    TX  San Antonio            0             Facility   \n",
      "3997    MT     Billings            0             Facility   \n",
      "3998    TX        Bryan            1             Facility   \n",
      "3999    TX   Fort Worth            1             Provider   \n",
      "\n",
      "                   provider_specialty        date part_1 part_2  \\\n",
      "0                  Forensic Pathology  2024-07-01     TX   CAID   \n",
      "1              Allergy and Immunology  2024-07-01     TX   CAID   \n",
      "2                   Internal Medicine  2024-07-01     TX   CAID   \n",
      "3                          Cardiology  2024-07-01     TX   CAID   \n",
      "4              Allergy and Immunology  2024-07-01     TX   CAID   \n",
      "...                               ...         ...    ...    ...   \n",
      "3995  Hospice and Palliative Medicine  2024-07-15     TX     MA   \n",
      "3996               Emergency Medicine  2024-07-15     TX     MA   \n",
      "3997  Hospice and Palliative Medicine  2024-07-15     TX     MA   \n",
      "3998  Hospice and Palliative Medicine  2024-07-15     TX     MA   \n",
      "3999               Emergency Medicine  2024-07-15     TX     MA   \n",
      "\n",
      "               part_3  \n",
      "0        Network3 90%  \n",
      "1        Network3 90%  \n",
      "2        Network3 90%  \n",
      "3        Network3 90%  \n",
      "4        Network3 90%  \n",
      "...               ...  \n",
      "3995  H09156 Network2  \n",
      "3996  H09156 Network2  \n",
      "3997  H09156 Network2  \n",
      "3998  H09156 Network2  \n",
      "3999  H09156 Network2  \n",
      "\n",
      "[4000 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import fnmatch\n",
    "import os\n",
    "import re\n",
    "from dateutil import parser\n",
    "from dateutil.parser import ParserError\n",
    "\n",
    "# Patterns to match Excel files in the data directory and its subdirectories\n",
    "data_patterns = ['data/*.xlsx', 'data/**/*.xlsx']\n",
    "\n",
    "# Initialize an empty DataFrame\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "def extract_date_from_filename(filename):\n",
    "    # Define possible date patterns\n",
    "    date_patterns = [\n",
    "        r'\\d{4}-\\d{2}-\\d{2}',  # YYYY-MM-DD\n",
    "        r'\\d{2}-\\d{2}-\\d{4}',  # DD-MM-YYYY or MM-DD-YYYY\n",
    "        r'\\d{2}_\\d{2}_\\d{4}',  # DD_MM_YYYY or MM_DD_YYYY\n",
    "        r'\\d{1,2}-\\d{1,2}-\\d{2,4}',  # D-M-YY or MM-DD-YY\n",
    "        r'\\d{1,2}_\\d{1,2}_\\d{2,4}',  # D_M_YY or MM_DD_YY\n",
    "        r'\\d{8}',  # YYYYMMDD\n",
    "        r'\\d+\\.\\d+\\.\\d+'  # Dates with periods (e.g., 01.02.2023)\n",
    "    ]\n",
    "    for pattern in date_patterns:\n",
    "        matches = re.findall(pattern, filename)\n",
    "        for date_str in matches:\n",
    "            try:\n",
    "                parsed_date = parser.parse(date_str, dayfirst=False)\n",
    "                return parsed_date.strftime('%Y-%m-%d')\n",
    "            except ParserError:\n",
    "                continue\n",
    "    print(f\"No valid date found in filename: {filename}\")\n",
    "    return 'Unknown'\n",
    "\n",
    "\n",
    "def split_filename(filename):\n",
    "    parts = filename.split(\"_\")\n",
    "    return parts[:3]  # Only return the first three parts\n",
    "\n",
    "\n",
    "# Collect all Excel files from the data directory and its subdirectories\n",
    "excel_files = []\n",
    "for pattern in data_patterns:\n",
    "    excel_files.extend(glob.glob(pattern, recursive=True))\n",
    "\n",
    "# Remove duplicates in case of overlap\n",
    "excel_files = list(set(excel_files))\n",
    "\n",
    "# Using glob to find all xlsx files in the main directory and all subdirectories\n",
    "for filepath in excel_files:\n",
    "    print(f\"Checking file: {filepath}\")\n",
    "    try:\n",
    "        xls = pd.ExcelFile(filepath)\n",
    "        print(f\"Sheets available in {filepath}: {xls.sheet_names}\")\n",
    "        sheet_name = next(\n",
    "            (sheet for sheet in xls.sheet_names if fnmatch.fnmatch(sheet, '*')),\n",
    "            None\n",
    "        )\n",
    "        if sheet_name:\n",
    "            df = pd.read_excel(filepath, sheet_name=sheet_name)\n",
    "            # Standardize column names\n",
    "            df.columns = df.columns.str.strip().str.lower()\n",
    "            # Print column names for debugging\n",
    "            print(f\"Columns in sheet {sheet_name}: {df.columns.tolist()}\")\n",
    "            if 'metoverall' in df.columns or 'metaccess' in df.columns:\n",
    "                # Combine 'metoverall' and 'metaccess' into a single column\n",
    "                if 'metoverall' in df.columns:\n",
    "                    df['metcombined'] = df['metoverall']\n",
    "                else:\n",
    "                    df['metcombined'] = df['metaccess']\n",
    "                df['metcombined'] = df['metcombined'].map({1: 1, 0: 0})     # map \"Y\" to 1 and \"N\" to 0 -- df['metcombined'] = df['metcombined'].map({\"Y\": 1, \"N\": 0})\n",
    "                # Define column sets\n",
    "                required_columns = ['state', 'county', 'metcombined']                   # required_columns = ['countyname', 'metcombined']\n",
    "                opt_columns = {\n",
    "                    'provider_or_facility': ['facility or provider', 'provider or facility'],   # determine columns to search for\n",
    "                    'provider_specialty': ['providertype', 'specdesc']                          # determine columns to search for\n",
    "                }   \n",
    "\n",
    "                # Check and add optional columns\n",
    "                for key, cols in opt_columns.items():\n",
    "                    col_to_add = next((col for col in cols if col in df.columns), None)\n",
    "                    if col_to_add:\n",
    "                        df[key] = df[col_to_add]\n",
    "\n",
    "                # Ensure required columns are present\n",
    "                subset_df = df[required_columns].copy()\n",
    "\n",
    "                # Add optional columns\n",
    "                for key in opt_columns.keys():\n",
    "                    if key in df.columns:\n",
    "                        subset_df[key] = df[key]\n",
    "\n",
    "                # Extract date and parts from the filename\n",
    "                subset_df['date'] = extract_date_from_filename(filepath)\n",
    "                parts = split_filename(os.path.basename(filepath))\n",
    "                for i in range(len(parts)):\n",
    "                    subset_df[f'part_{i + 1}'] = parts[i] if len(parts) > i else 'Unknown'\n",
    "\n",
    "                combined_df = pd.concat([combined_df, subset_df], ignore_index=True)\n",
    "            else:\n",
    "                print(f\"'MetOverall' or 'MetAccess' column not found in sheet {sheet_name}.\")\n",
    "        else:\n",
    "            print(f\"No matching sheet name found in {filepath}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {filepath}: {e}\")\n",
    "print(\"Combined DataFrame:\")\n",
    "print(combined_df)\n",
    "# Save the merged DataFrame to a CSV file\n",
    "combined_df.to_csv('combined_adequacy_detail.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a04560a0c234d9f9217742ffff3dc94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QgridWidget(grid_options={'fullWidthRows': True, 'syncColumnCellResize': True, 'forceFitColumns': True, 'defauâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import qgrid\n",
    "qgrid.show_grid(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  state       county  metcombined provider_or_facility  \\\n",
      "0    TX     Amarillo            1             Provider   \n",
      "1    TX      El Paso            1             Provider   \n",
      "2    MT     Missoula            1             Provider   \n",
      "3    TX      Lubbock            1             Facility   \n",
      "4    NM  Albuquerque            0             Provider   \n",
      "\n",
      "       provider_specialty        date part_1 part_2        part_3  \n",
      "0      Forensic Pathology  2024-07-01     TX   CAID  Network3 90%  \n",
      "1  Allergy and Immunology  2024-07-01     TX   CAID  Network3 90%  \n",
      "2       Internal Medicine  2024-07-01     TX   CAID  Network3 90%  \n",
      "3              Cardiology  2024-07-01     TX   CAID  Network3 90%  \n",
      "4  Allergy and Immunology  2024-07-01     TX   CAID  Network3 90%  \n",
      "\n",
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4000 entries, 0 to 3999\n",
      "Data columns (total 9 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   state                 4000 non-null   object\n",
      " 1   county                4000 non-null   object\n",
      " 2   metcombined           4000 non-null   int64 \n",
      " 3   provider_or_facility  4000 non-null   object\n",
      " 4   provider_specialty    4000 non-null   object\n",
      " 5   date                  4000 non-null   object\n",
      " 6   part_1                4000 non-null   object\n",
      " 7   part_2                4000 non-null   object\n",
      " 8   part_3                4000 non-null   object\n",
      "dtypes: int64(1), object(8)\n",
      "memory usage: 281.4+ KB\n",
      "None\n",
      "\n",
      "DataFrame has been saved to 'combined_df_output.csv'\n"
     ]
    }
   ],
   "source": [
    "# Remove or comment out the qgrid-related lines\n",
    "# import qgrid\n",
    "# qgrid.show_grid(combined_df)\n",
    "\n",
    "# Instead, use these lines to display your DataFrame\n",
    "print(combined_df.head())  # Display the first 5 rows\n",
    "print(\"\\nDataFrame Info:\")\n",
    "print(combined_df.info())  # Display information about the DataFrame\n",
    "\n",
    "# If you want to see all columns, you can use:\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# print(combined_df)\n",
    "\n",
    "# If you want to save the DataFrame to a CSV file for easier viewing:\n",
    "combined_df.to_csv('combined_df_output.csv', index=False)\n",
    "print(\"\\nDataFrame has been saved to 'combined_df_output.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "untitled",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
